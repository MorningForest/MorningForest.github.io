---
layout:     post
title:      "信息熵"
subtitle:   "了解信息熵"
date:       2019-11-17 18:50:00
author:     "hjw"
header-img: "img/information.jpg"
tags:
    - 信息熵
---

### 信息熵的理解

#### 信息量

平常我们所讲的信息是很抽象的概念，究竟什么是信息？在百度百科定义中为音讯，消息，通讯系统传输和处理对象，泛指人类社会传播的一切内容。信息是看不见摸不着的，那该怎么把信息量化？

此时引入信息量的概念，首先必须明确的是信息是不存在负的，因为不可能不存在信息的物质，反而会偷走信息。其实从现实生活中可知，如果一件事是确定的，那么它所含有信息量就很少，反之若存在不确定性越大，那么所含信息量就越大。如人类要吃饭，这句话几乎没有信息；又如明天某支股票有70%纪律会上升，这句话包含信息量大。既然信息量跟不确定因素有关，那么不确定因素又跟什么有关系呢？

##### 不确定因素的变化

+ 事情的结果。因为如果事件的结果只有一个，那么这就是确定的结果，也就是说不含任何信息量了。但如果出现多种结果，那么不确定因素就很大，其包含信息自然就很大。
+ 概率的大小。关于多种结果不能定量衡量不确定因素的大小，考虑一下一种情况，如桌子上有苹果，香蕉和草莓三种水果，小明随机吃一个水果。出现情况有三种，但是如果我们知道小明吃苹果概率为99%,在大多数情况下，你告诉我们小明吃水果信息没什么用，因为小明吃苹果概率很高，不确定因素很低，信息量低。

##### 信息量的特点

+ 之前提过信息量一定是正数，因为不可能存在负信息的情况。
+ 信息量之间可以相加。考虑下面一种情况：对于两个不相关事件，分别有信息量P(A)和P(B),那么那么事件同时发生获得信息P(AB)=P(A)+P(B).此时我们可以知道信息量公式一定跟对数有关系。
+ 信息量连续依赖于概率且成负关系。我们从上面例子知道，但吃苹果概率发生变化时，其信息量也会随着连续变化。且如果吃苹果概率变小，那么这件事件信息量就会变大，即<img src="http://latex.codecogs.com/gif.latex?information \propto \frac{1}{probability}">
+ 信息量跟可能的结果有关系。当事件出现结果丰富时，其本身包含信息量必然很巨大。

##### 信息量计算公式

从上面谈论中，我们了解到信息量跟概率之间关系。接下来给出信息量计算公式
<img src="http://latex.codecogs.com/gif.latex?h(x)=-\log(p(x))">

#### 信息熵

##### 理论提出

香农在1948年发表的论文“通信的数学理论”中指出，任何信息都存在冗余，冗余大小与信息中每个符号的出现概率或者说不确定性有关。香农借鉴了热力学的概念，把信息中排除了冗余后的平均信息量称为信息熵，并给出了数学计算公式

##### 信息熵公式

信息量度量的是一个具体事件发生了所带来的信息，而熵是在结果出来之前对所有可能产生的信息量的期望。
<img src="http://latex.codecogs.com/gif.latex?
H(x)=-\sum_{i=1}^{n}p(x_i)\log(p(x_i))">

##### 信息熵理解

+ 信息熵用来衡量信息量的大小，是消除不确定性所需信息量的度量

+ 若不确定性越大，信息量越大，熵越大，反之。

+ 信息熵也可以作为系统复杂程度的度量，若系统越复杂，出现不同情况的种类越多，信息熵越大，反之亦然。极端情况下系统出现情况为1，则信息熵为0.

  



